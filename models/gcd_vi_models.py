
# 
import numpy as np
import scipy as sp
import scipy.sparse.linalg as sp_s_linalg
import scipy.linalg as sp_linalg
from scipy.sparse import coo_matrix,csr_matrix, hstack, vstack, find

# 
import utils.gcd_utils as gcd_utils




def autotune_epsilon(X1,X2,L_G):
    n, c1 = X1.shape
    X2 = X2/np.sqrt(np.sum(X2**2,axis=0))
    #epsilon = []
    epsilon = 0
    delta0 = np.zeros((n,c1))
    for i in range(c1):
        tmp = X1[:,i].reshape((n,1))
        norm_tmp = np.sqrt(np.sum(X1[:,i]**2))
        delta_tmp = X2*norm_tmp - tmp      
        if i > 0:
            delta0[:,i] = np.mean(delta_tmp,axis=1)
            epsilon = epsilon + np.mean(np.sqrt(np.sum((L_G @ delta_tmp)**2,axis=0)))
        else:
            delta0[:,i] = np.mean(delta_tmp,axis=1)
        #epsilon_tmp = np.mean(np.sqrt(np.sum((L_G @ delta0)**2,axis=0)))
            epsilon = np.mean(np.sqrt(np.sum((L_G @ delta_tmp)**2,axis=0))) #epsilon + epsilon_tmp
        #epsilon.append(np.mean(epsilon_tmp.flatten()))

    return epsilon/c1, delta0



def unsupervised_cd_estimation(X2,W1,W,alg_param):
    """ estimates labels at the unlabeled nodes of the graph G with adj. matrix W
        using a particular instance of Algorithm 1 defined in the manuscript: 
        Exploiting variational inequalities for generalized CD. 
        
        Parameters:
        X2 (2-D ndarray): matrix of size n by c2 with post-event avg signals.
        W1 (2-D sparse array): n by n adjacency matrix of graph on which avg preevent signals are suff. smooth
        W (2-D sparse array): n by n adjacency matrix of graphs
        alg_param (dict): dictionary structure given by 
                          alg_param = {'basis_param': <(basis_name,dim)>
                                       'C_param': <(norm_type,offset_vector,radius)>,
                                       'maxit': <positive integer>,
                                       'gamma0': <real value in (0,2)>
                                       'reversed': <True or False>},
        Returns:
            x1, delta (2D ndarray): pre-event and diff signal estimates of size n by c2 (i.e., X2.shape).
            history (dict): tracks the evolution of optimization terms across iterations

        Author: 
        Juan Felipe Florez Ospina
        Email: juanflo16@gmail.com, jfflorez@udel.edu     
        Last-updated: May 23, 2023
        """
    
    if not 'display_iter' in alg_param.keys():
        alg_param['display_iter'] = True 
    if not 'disp_factor' in alg_param.keys():
        alg_param['disp_factor'] = 1

    # Validate datasize
    if X2.ndim > 1:
        if X2.ndim <= 2: 
            n, c2 = X2.shape
        else:
            raise ValueError('X_mean_2 must be a 2-dim array of shape (n,c)')       
    else:
        n = len(X2)
        c2 = 1
        X2 = X2.reshape((n,1))    
    
        
    # Compute graph based linear operator H1
    #U, SS = gcd_utils.construct_subspace(W2, param ={'basis_params':('sc',n)})
    #U = U@np.diag(1/np.sqrt(SS))

    if 'basis_params' in alg_param:
        U = gcd_utils.construct_subspace(W1, param = alg_param)
    else:
        U = gcd_utils.construct_subspace(W1, param ={'basis_params':('RLP',n)})
    if isinstance(U,tuple):
        U, SS = U
    #U = U@np.diag(1/np.sqrt(SS))

    k = U.shape[1]

    # Compute L_G
    D = sp.sparse.spdiags(np.sum(W,1).squeeze(),0, W.shape[0], W.shape[1])
    L_G= D - W

    norm, w0, r = alg_param['C_params']
    radius = [r for i in range(c2)]
    #sp_level = [s for i in range(c1)]
    if 'X1' in alg_param: # we can estimate epsilon
        #epsilon_avg = autotune_epsilon(X1,alg_param['X2'],L_G)
        #epsilon = [epsilon_avg for i in range(c1)] 
        epsilon, delta0 = autotune_epsilon(X2,alg_param['X1'],L_G)
    else:
        #epsilon = [0.1 for i in range(c1)]  
        epsilon = 0.1 

    norm_2_func = lambda x: np.sqrt(np.sum(x**2,axis=0)) 
        #norm = '2-1'
    if norm == 'inf':
        norm_func = lambda x: np.max(np.abs(x.squeeze()),axis=0)
        proj_C1 = lambda x,r: r*((x/r) - np.sign(x/r)*np.maximum(0,np.abs(x/r)-1))
        #    proj_C = lambda x,r: x - r*np.sign(x/r)*np.maximum(0,np.abs(x/r)-1)
    elif norm == '2':
        norm_func = lambda x: np.sqrt(np.sum(x**2,axis=0))         
        proj_C1 = lambda x, r: x/np.maximum(1,sp_linalg.norm(x/r,2,axis=0))
    elif norm == '1':        
        norm_func = lambda x: np.sum(np.abs(x),axis=0)
        def find_th(y,a):
            u = -1*np.sort(-y,axis=0).squeeze()
            k = 1
            #acum = np.zeros(u.shape) #
            acum = -np.infty
            while acum < u[k-1] and k < len(u):                    
                #for k in range(1,len(u)+1):                    
                acum = (np.sum(u[0:(k-1)])-a)/k 
                k += 1
                        #acum[k] = np.sum(u[0:k]-a)/(k+1) < u[k]
                return acum #(np.sum(u[0:k])-a)/k
        def proj_C1(x,r):
            x = x/r                
            if sp_linalg.norm(x,1,axis=0) > 1:
                th = find_th(np.abs(x),1)
                x = np.sign(x)*np.maximum(0, np.abs(x) - th)                
            return r*x

    proj_C2 = lambda x: x

    proj_C = lambda x,r: np.vstack((proj_C1(x[0:n],r),proj_C2(x[n:2*n])))



    # first part is w and second part is delta
    phi_1 = lambda x,x1: x - x1 
    phi_2 = lambda x, epsilon: x - np.vstack((x[0:n,:], x[n:2*n,:]/np.maximum(1,sp_linalg.norm(x[n:2*n,:]/epsilon,2,axis=0)))) #proj_C(x,epsilon)

    # Set initial guess and loop params
    maxit = alg_param['maxit']
    #x0 = [np.zeros((2*n,1)) for i in range(c1)]
    x0 = np.zeros((k+n,c2))
    #x0[n:2*n,:] = delta0
    #x0 = 0.1*np.random.randn(2*n,1)

    if alg_param['reversed']==True:
        H1 = np.hstack((U,-np.eye(n,n)))
    else:
        H1 = np.hstack((U, np.eye(n,n)))
    H2 = vstack( ( hstack((np.eye(k,k),csr_matrix((k,n)))), hstack((csr_matrix((n,k)),L_G)) ) )
        #H2 = hstack((csr_matrix((n,n)),L_G))  

    norms = np.array([sp.linalg.norm(H1,ord=2),sp.linalg.norm(L_G.toarray(),ord=2)])

    #gamma = alg_param['gamma0']/(norms**2)
    gamma = 1/(norms**2)
        #Gamma = np.diag(gamma)  
    w1 = 1/2
    w2 = 1 - w1

    #x1 = [X1[:,i].reshape((n,1)) for i in range(c1)]
    #x = []
    #x0 = np.zeros((2*n,c1))
    x = np.zeros((k+n,c2))
    x2 = X2

    MAXIT = maxit + int(maxit*0.5)
    history = {'r_0':r,'epsilon_0':epsilon,'phi_1':np.zeros((MAXIT,1)),'phi_2':np.zeros((MAXIT,1)),'norm_w':np.zeros((MAXIT,1))}
    for epoch in range(MAXIT):  

        history['phi_1'][epoch] = np.mean(norm_2_func(phi_1(H1@x0,x2)))
        history['phi_2'][epoch] = np.mean(norm_2_func(phi_2(H2@x0,epsilon)))
        history['norm_w'][epoch] = np.mean(norm_func(x0[0:n,:]))

        # TODO: include code to track the performance of the estimator as a function of 
        # iterations 
        # if alg_param['log_metrics'] == True and 'gt' in alg_param:
        #    score_map = gcd_utils.spixels_upsampling(np.sqrt(np.sum((delta)**2,axis=1)).reshape((n,1)),
        #                                             alg_param['segments'])
        #    ref_fpr = 0.05
        #    metrics_dict = gcd_utils.compute_performance_metrics(alg_param['gt'], score_map,ref_fpr)


        if alg_param['display_iter'] and epoch%alg_param['disp_factor']==0:  
            print('iter:', str(epoch), 'phi_1:', history['phi_1'][epoch], 'phi_2:', history['phi_2'][epoch])

        t1 = x0 - gamma[0]*H1.T@(phi_1(H1@x0,x2)-0)  
        t2 = x0 - gamma[1]*H2.T@(phi_2(H2@x0,epsilon)-0)

        for i in range(c2):
            acum = w1*t1[:,i] + w2*t2[:,i]
            x[:,i] = proj_C(acum.reshape((k+n,1)), r).flatten()

        #for i in range(c1):
        #    t1 = x0[i] - gamma[0]*H1.T@(phi_1(H1@x0[i],x1[i])-0)
        #    t2 = x0[i] - gamma[1]*H2.T@(phi_2(H2@x0[i],epsilon[i])-0)
        #    if epoch > 0:
        #        x[i] = proj_C(w1*t1 + w2*t2, radius[i], sp_level[i])      
        #    else:
        #        x.append(proj_C(w1*t1 + w2*t2, radius[i], sp_level[i]))

        #x = np.sqrt(p_ask)*x/sp_linalg.norm(x,2,axis=0) if sp_linalg.norm(x,2,axis=0) > np.sqrt(p_ask) else x

        
        #print('iter:', str(epoch), sp_linalg.norm(sigmoid((U @ x)[idx_train])-y_train), sp_linalg.norm(x))
        #print('iter:', str(epoch), sp_linalg.norm(phi((U @ x)[idx_train]).squeeze()-y_train), norm_func(x))

        x0 = x  

        if (epoch == maxit):
            r = np.mean(norm_func(x[0:k,:]))*0.75 #(0.75-0.5)
            epsilon = np.mean(norm_2_func(L_G@x[k:2*n,:]))*0.15 #0.15
            #r = np.mean(norm_func(x[0:n,:])*0.55)
            #epsilon = np.mean(norm_2_func(L_G@x[n:2*n,:]))*0.15
            history['r'] = r
            history['epsilon'] = epsilon
            #epsilon = np.minimum(0.1, np.mean(norm_2_func(L_G@x[n:2*n,:]))*0.65)
            #radius = [norm_2_func(x[i][0:n])*0.65 for i in range(c1)]
            #epsilon = [norm_2_func(L_G@x[i][n:2*n])*0.65 for i in range(c1)]


    #x2 = U@(np.diag(1/np.sqrt(SS))@x[0:n,:])
    x1 = U@x[0:k,:]
    delta = x[k:2*n,:]

    return x1, delta, history



def semisup_cd_estimation(y_train,idx_train,W,alg_param):
        """ estimates labels at the unlabeled nodes of the graph G with adj. matrix W
        using a particular instance of Algorithm 1 defined in the manuscript: 
        Exploiting variational inequalities for generalized CD. 
        
        Parameters:
        y_train (ndarray): one dimensional numpy array of size m s.t. 2<= m <n with training labels
        idx_train (ndarray): one dimensional numpy array of size m with indices of the labeled nodes 
        W (2-D sparse array): n by n adjacency matrix of graphs
        alg_param (dict): dictionary structure given by 
                          alg_param = {'basis_param': <(basis_name,dim)>
                                       'C_param': <(norm_type,offset_vector,radius)>,
                                       'maxit': <positive integer>,
                                       'gamma0': <real value in (0,2)>}.
        Returns:
            f_hat, prob_hat (narray): one dimensional numpy arrays of size n with estimated labels at 
            a threshold of 0.5 and estimated probabilites.   

        Author: 
        Juan Felipe Florez Ospina
        Email: juanflo16@gmail.com, jfflorez@udel.edu     
        Last-updated: May 23, 2023
        """


        n = W.shape[0]
        m = len(y_train)
        #m = S.shape[0]

        if not 'display_iter' in alg_param.keys():
            alg_param['display_iter'] = True 
        if not 'disp_factor' in alg_param.keys():
            alg_param['disp_factor'] = 1

        #f_hat, p_ask = gsm_estimation(S,F,W)

        idx = np.arange(0,len(idx_train))
        I_pos = idx[y_train==1]
        I_neg = idx[y_train==0]

        m_pos = np.min([len(I_neg),len(I_pos)])
        I = []
        for i in range(m_pos):
            I.append(np.array([I_pos[i],I_neg[i]]))



        #method = 'sc'
        #method = 'nystrom'
        #k = int(m/2)
        #k = int(m/3)
        #k = m

        #alg_param = {'truncation_param': k,'maxit': n, 'p_ask': p_ask}

        #method = 'smoothness_prior'


        U = gcd_utils.construct_subspace(W, param = alg_param)  
        if isinstance(U,tuple):
            S = U[1]
            U = U[0]
        k = U.shape[1]

        #L_2 = sp_linalg.inv(U.T@U)@U.T



        #f = 1-np.argmax(F,axis=1)
        #y = S @ f
        #y = y.reshape((m,1))

        #U_norm = np.sqrt(np.sum(U**2,axis=0))
        #U_norm[U_norm==0] = 1
        #U = U/U_norm

        #norm = 'inf'
        #norm = '1'
        norm, w0, radius = alg_param['C_params']
        if norm == 'inf':
            norm_func = lambda x: np.max(np.abs(x.squeeze()))
            #proj_C = lambda x,r: r*((x/r) - np.sign(x/r)*np.maximum(0,np.abs(x/r)-1))
            proj_C = lambda x,r: x - r*np.sign(x/r)*np.maximum(0,np.abs(x/r)-1)
        elif norm == '2':
            norm_func = lambda x: np.sqrt(np.sum(x.squeeze()**2))
            #proj_C = lambda x, r: r*(x/r)/np.maximum(1,sp_linalg.norm(x/r,2,axis=0))
            proj_C = lambda x, r: x/np.maximum(1,sp_linalg.norm(x/r,2,axis=0))
        elif norm == '1':
            norm_func = lambda x: np.sum(np.abs(x.squeeze()))
            def find_th(y,a):
                u = -1*np.sort(-y,axis=0).squeeze()
                k = 1
                #acum = np.zeros(u.shape) #
                acum = -np.infty
                while acum < u[k-1] and k < len(u):                    
                #for k in range(1,len(u)+1):                    
                    acum = (np.sum(u[0:(k-1)])-a)/k 
                    k += 1
                    #acum[k] = np.sum(u[0:k]-a)/(k+1) < u[k]
                return acum #(np.sum(u[0:k])-a)/k
            def proj_C(x,r):
                x = x/r
                
                if sp_linalg.norm(x,1,axis=0) > 1:
                    th = find_th(np.abs(x),1)
                    x = np.sign(x)*np.maximum(0, np.abs(x) - th)                
                return r*x

        w1 = 2/3
        w2 = 1 - w1
        c = 40 # l2 ball radious
        c = 500
        #softmax = lambda x: np.exp(x)/np.reshape(np.sum(np.exp(x),axis=1),(x.shape[0],1))
        #phi = lambda x: x

        phi = lambda x: 1/(1+np.exp(-x))-1/2
        y_train = y_train - 1/2
        
        

        #gamma0 = alg_param['gamma0'] #1e1
        #gamma = gamma0/np.sum((S @ U)**2,axis=1)
        #gamma = gamma0/np.sum((U[idx_train,:])**2,axis=1)
        #gamma = gamma.reshape((m,1))
        #gamma = (2/np.max(np.sum((U[idx_train,:])**2,axis=1))-0)/2

        # Set initial guess and loop params
        maxit = alg_param['maxit']
        x0 = np.zeros((k,1))
        #x0 = 0.001*np.random.randn(k,1)
        gamma = alg_param['gamma0']/np.sum((U[idx_train,:])**2,axis=1)

        Gamma = np.diag(gamma)  
        U_s = U[idx_train,:]
        #t1 = np.zeros((k,m))
        for epoch in range(maxit + int(maxit*0.5)):             
            #for i in range(m):
            #for i in I[epoch % m_pos]: 

            #    e_i = np.zeros((1,n))
            #    e_i[0,idx_train[i]] = 1
            #    t1[:,i] = (x0 - gamma[i]*(U.T@(e_i.T@(phi(e_i @ (U @ x0))-y_train[i])))).flatten()

            #U_s = U[I[epoch % m_pos],:]
            #y_s = y_train[I[epoch % m_pos]]
            #m_s = len(y_s)
            #Gamma_s = np.diag(gamma[I[epoch % m_pos]]) 
            #t1[:,I[epoch % m_pos]] = x0 - U_s.T * (Gamma_s @ (phi(U_s@x0)-y_s.reshape((m_s,1)))).reshape((1,m_s))
            t1 = x0 - U_s.T * (Gamma @ (phi(U_s@x0)-y_train.reshape((m,1)))).reshape((1,m))

            #t2 = x0 - gamma0*((x0 - proj_l2B(x0,np.sqrt(p_ask))) - 0)
            #x = np.sum(t1,axis=1).reshape((k,1))/(m+1) + t2/(m+1)

            x = np.sum(t1,axis=1).reshape((k,1))/m          
            #x = proj_l2B(x,p_ask)
            
            x = proj_C(x, radius)

            #x = np.sqrt(p_ask)*x/sp_linalg.norm(x,2,axis=0) if sp_linalg.norm(x,2,axis=0) > np.sqrt(p_ask) else x
            
            #print('iter:', str(epoch), sp_linalg.norm(sigmoid((U @ x)[idx_train])-y_train), sp_linalg.norm(x))
            
            if alg_param['display_iter'] and epoch%alg_param['disp_factor']==0:    
                print('iter:', str(epoch), sp_linalg.norm(phi((U @ x)[idx_train]).squeeze()-y_train), norm_func(x))

            #if epoch <= maxit:
            x0 = x  
            #else:
            #    alpha = 0.1
            #    x0 = (1-alpha)*x0old + alpha*x

            #if (epoch == maxit):
            #    break

            if (epoch == maxit):
                radius = norm_func(x)*0.75 #(norm_func(x)+p_ask/np.sqrt(n))/2

        probs_hat = phi(U@x)+1/2
        f_hat = np.zeros(probs_hat.shape)
        f_hat[probs_hat>0.5] = 1
        f_hat[probs_hat<=0.5] = 0

        return f_hat, probs_hat



